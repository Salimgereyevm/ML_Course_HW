{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2Vec.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1yQZ2P3s-tOQ2oIC_uJCKYlOyn6qkW7M0",
      "authorship_tag": "ABX9TyMJsH6WxFd66lErvWBoSgUj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Salimgereyevm/SalimgereyevM309/blob/master/Word2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrKQq_0QmazM",
        "colab_type": "code",
        "outputId": "5ac469b3-5526-44fd-d472-0de0c67e08cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU0GFqoZaH3m",
        "colab_type": "code",
        "outputId": "b0d178b3-e80a-4cf4-f9de-bc57bccb650d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/My Drive/Word2Vec/train.csv\", index_col=0)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I think they really let the quality of the DVD...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I'm sorry but this is just awful. I have told ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Japenese sense of pacing, editing and musi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In the '60's/'70's, David Jason was renowned f...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"Hail The Woman\" is one of the most moving fil...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  label\n",
              "0  I think they really let the quality of the DVD...      0\n",
              "1  I'm sorry but this is just awful. I have told ...      0\n",
              "2  The Japenese sense of pacing, editing and musi...      0\n",
              "3  In the '60's/'70's, David Jason was renowned f...      1\n",
              "4  \"Hail The Woman\" is one of the most moving fil...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEYkSaBWnNr9",
        "colab_type": "code",
        "outputId": "04c89c78-b881-4136-ebb7-8b95877bbe8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "en_stop = list(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer() \n",
        "\n",
        "def tokenize(text):\n",
        "    tokens = nltk.word_tokenize(text.lower())\n",
        "    tokens = [t for t in tokens if\n",
        "              re.match(r'[^\\W\\d]*$', t) and (len(t) > 2) and (t not in en_stop)]\n",
        "    tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
        "    return tokens\n",
        "\n",
        "tokens = df['review'].apply(tokenize) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXnGWT3rnYe0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "model = Word2Vec(tokens, size=300, window=6, min_count=4, iter=100, sg = 0, sample = 1e-5) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-YqGLvjZVjR",
        "colab_type": "code",
        "outputId": "bc6d9361-1183-4715-acb6-08de9121aeeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from scipy import stats\n",
        "\n",
        "def encode(list_of_tokens):\n",
        "    x = np.array([model.wv[t] for t in list_of_tokens if t in model.wv.vocab])\n",
        "    u = [np.mean(x, axis=0), np.median(x, axis = 0)]\n",
        "    return np.concatenate(u)\n",
        "fts = np.array([encode(t) for t in tokens])\n",
        "fts.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40000, 600)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m6qMn6aZW68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(fts, df.label.values,\n",
        "                                                    test_size=0.2, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bugOLpRH_Oe6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import svm\n",
        "clf1 = svm.SVC().fit(fts, df.label.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EizT9XuvZ1h4",
        "colab_type": "code",
        "outputId": "daeee634-8d9d-4260-fa1f-a7895027fbfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# predicts = clf1.predict(X_train)\n",
        "# print('Train\\n', classification_report(y_train, predicts))\n",
        "\n",
        "predicts = clf1.predict(X_test)\n",
        "print('Test\\n', classification_report(y_test, predicts, digits = 4))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9276    0.9154    0.9215      4056\n",
            "           1     0.9142    0.9265    0.9203      3944\n",
            "\n",
            "    accuracy                         0.9209      8000\n",
            "   macro avg     0.9209    0.9210    0.9209      8000\n",
            "weighted avg     0.9210    0.9209    0.9209      8000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fj_JoVugPBuv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = pd.read_csv('/content/drive/My Drive/Word2Vec/test.csv',index_col = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rpUKFNtQRcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tok = test['review'].apply(tokenize)\n",
        "mm = np.array([encode(t) for t in tok])\n",
        "predicted = clf1.predict(mm)\n",
        "pd.DataFrame({'Predicted' : predicted}).to_csv('/content/drive/My Drive/Word2Vec/solutionsvc.csv', index_label = 'Id')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}